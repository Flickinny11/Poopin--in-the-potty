#!/bin/bash

# =================================================================
# VidLiSync Production Load Testing Script
# =================================================================
# Tests the production system under realistic load conditions

set -euo pipefail

# Configuration
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
RESULTS_DIR="/tmp/load-test-results-$(date +%Y%m%d-%H%M%S)"
BASE_URL="${BASE_URL:-https://vidlisync.com}"
API_URL="${API_URL:-https://vidlisync-backend.railway.app}"
AI_URL="${AI_URL:-https://ai.vidlisync.com}"

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m'

log() {
    echo -e "${BLUE}[$(date +'%Y-%m-%d %H:%M:%S')]${NC} $1"
}

error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

# Setup
setup() {
    log "Setting up load test environment..."
    mkdir -p "$RESULTS_DIR"
    
    # Install artillery if not present
    if ! command -v artillery &> /dev/null; then
        log "Installing Artillery.js..."
        npm install -g artillery
    fi
    
    # Install k6 if not present
    if ! command -v k6 &> /dev/null; then
        log "Installing k6..."
        curl -s https://github.com/grafana/k6/releases/download/v0.47.0/k6-v0.47.0-linux-amd64.tar.gz | tar xvz --strip-components 1
        sudo mv k6 /usr/local/bin/
    fi
    
    success "Load test environment ready"
}

# Artillery configuration generator
generate_artillery_config() {
    local test_name=$1
    local target_url=$2
    local duration=${3:-300}
    local rate=${4:-10}
    
    cat > "$RESULTS_DIR/artillery-$test_name.yml" << EOF
config:
  target: '$target_url'
  phases:
    - duration: 60
      arrivalRate: 1
      name: "Warm up"
    - duration: $duration
      arrivalRate: $rate
      name: "Sustained load"
    - duration: 60
      arrivalRate: 50
      name: "Spike test"
  defaults:
    headers:
      User-Agent: 'VidLiSync LoadTest'
  processor: ./processor.js

scenarios:
  - name: "Health check"
    weight: 30
    requests:
      - get:
          url: '/health'
          
  - name: "Homepage"
    weight: 40
    requests:
      - get:
          url: '/'
          
  - name: "API endpoints"
    weight: 30
    requests:
      - get:
          url: '/api/health'
      - get:
          url: '/api/status'
EOF
}

# k6 script generator
generate_k6_script() {
    local test_name=$1
    local target_url=$2
    local vus=${3:-50}
    local duration=${4:-300s}
    
    cat > "$RESULTS_DIR/k6-$test_name.js" << EOF
import http from 'k6/http';
import { check, sleep } from 'k6';
import { Rate } from 'k6/metrics';

const errorRate = new Rate('error_rate');

export let options = {
  stages: [
    { duration: '30s', target: 10 },
    { duration: '${duration}', target: ${vus} },
    { duration: '30s', target: 0 },
  ],
  thresholds: {
    'http_req_duration': ['p(95)<2000'], // 95% of requests should be below 2s
    'error_rate': ['rate<0.05'], // Error rate should be below 5%
  },
};

export default function() {
  const baseUrl = '${target_url}';
  
  // Test homepage
  let response = http.get(\`\${baseUrl}/\`);
  check(response, {
    'homepage status is 200': (r) => r.status === 200,
    'homepage loads in <2s': (r) => r.timings.duration < 2000,
  }) || errorRate.add(1);
  
  sleep(1);
  
  // Test health endpoint
  response = http.get(\`\${baseUrl}/health\`);
  check(response, {
    'health status is 200': (r) => r.status === 200,
    'health responds in <200ms': (r) => r.timings.duration < 200,
  }) || errorRate.add(1);
  
  sleep(Math.random() * 2);
}
EOF
}

# Run frontend load test
test_frontend() {
    log "Running frontend load test..."
    
    generate_artillery_config "frontend" "$BASE_URL" 300 20
    generate_k6_script "frontend" "$BASE_URL" 100 300
    
    # Run Artillery test
    log "Running Artillery test for frontend..."
    artillery run "$RESULTS_DIR/artillery-frontend.yml" \
        --output "$RESULTS_DIR/artillery-frontend-results.json" || true
    
    # Generate Artillery report
    artillery report "$RESULTS_DIR/artillery-frontend-results.json" \
        --output "$RESULTS_DIR/artillery-frontend-report.html" || true
    
    # Run k6 test
    log "Running k6 test for frontend..."
    k6 run "$RESULTS_DIR/k6-frontend.js" \
        --out json="$RESULTS_DIR/k6-frontend-results.json" || true
    
    success "Frontend load test completed"
}

# Run backend API load test
test_backend() {
    log "Running backend API load test..."
    
    generate_artillery_config "backend" "$API_URL" 300 30
    generate_k6_script "backend" "$API_URL" 150 300
    
    # Create processor for authenticated requests
    cat > "$RESULTS_DIR/processor.js" << 'EOF'
module.exports = {
  setAuthToken: function(requestParams, context, ee, next) {
    // Add authentication token if available
    if (process.env.TEST_AUTH_TOKEN) {
      requestParams.headers = requestParams.headers || {};
      requestParams.headers['Authorization'] = \`Bearer \${process.env.TEST_AUTH_TOKEN}\`;
    }
    return next();
  }
};
EOF
    
    # Run Artillery test
    log "Running Artillery test for backend..."
    artillery run "$RESULTS_DIR/artillery-backend.yml" \
        --output "$RESULTS_DIR/artillery-backend-results.json" || true
    
    # Generate Artillery report
    artillery report "$RESULTS_DIR/artillery-backend-results.json" \
        --output "$RESULTS_DIR/artillery-backend-report.html" || true
    
    # Run k6 test
    log "Running k6 test for backend..."
    k6 run "$RESULTS_DIR/k6-backend.js" \
        --out json="$RESULTS_DIR/k6-backend-results.json" || true
    
    success "Backend load test completed"
}

# Run AI service load test
test_ai_service() {
    log "Running AI service load test..."
    
    generate_k6_script "ai" "$AI_URL" 50 180
    
    # Custom k6 script for AI service
    cat > "$RESULTS_DIR/k6-ai.js" << EOF
import http from 'k6/http';
import { check, sleep } from 'k6';
import { Rate } from 'k6/metrics';

const errorRate = new Rate('error_rate');

export let options = {
  stages: [
    { duration: '30s', target: 5 },
    { duration: '180s', target: 20 },
    { duration: '30s', target: 0 },
  ],
  thresholds: {
    'http_req_duration': ['p(95)<5000'], // AI requests can be slower
    'error_rate': ['rate<0.1'], // Higher error tolerance for AI
  },
};

export default function() {
  const baseUrl = '${AI_URL}';
  
  // Test health endpoint
  let response = http.get(\`\${baseUrl}/health\`);
  check(response, {
    'AI health status is 200': (r) => r.status === 200,
  }) || errorRate.add(1);
  
  sleep(2);
  
  // Test translation endpoint (if available)
  response = http.get(\`\${baseUrl}/api/translation/languages\`);
  check(response, {
    'languages endpoint accessible': (r) => r.status === 200 || r.status === 404,
  });
  
  sleep(Math.random() * 5);
}
EOF
    
    # Run k6 test
    log "Running k6 test for AI service..."
    k6 run "$RESULTS_DIR/k6-ai.js" \
        --out json="$RESULTS_DIR/k6-ai-results.json" || true
    
    success "AI service load test completed"
}

# Database stress test
test_database() {
    log "Running database stress test..."
    
    # Create database stress test script
    cat > "$RESULTS_DIR/db-stress-test.sql" << 'EOF'
-- Database stress test queries
BEGIN;

-- Test user queries
EXPLAIN ANALYZE SELECT * FROM users WHERE email = 'test@example.com';
EXPLAIN ANALYZE SELECT * FROM users WHERE subscription_tier = 'pro' LIMIT 100;

-- Test call queries
EXPLAIN ANALYZE SELECT * FROM calls WHERE host_user_id = '00000000-0000-0000-0000-000000000000' ORDER BY created_at DESC LIMIT 50;
EXPLAIN ANALYZE SELECT COUNT(*) FROM calls WHERE status = 'active';

-- Test usage logs queries
EXPLAIN ANALYZE SELECT SUM(duration_minutes) FROM usage_logs WHERE user_id = '00000000-0000-0000-0000-000000000000' AND billing_period = '2024-01';

-- Test complex joins
EXPLAIN ANALYZE 
SELECT u.email, COUNT(c.id) as call_count, SUM(ul.duration_minutes) as total_minutes
FROM users u
LEFT JOIN calls c ON u.id = c.host_user_id
LEFT JOIN usage_logs ul ON u.id = ul.user_id
WHERE u.created_at > NOW() - INTERVAL '30 days'
GROUP BY u.id, u.email
ORDER BY total_minutes DESC
LIMIT 100;

ROLLBACK;
EOF
    
    if [ -n "${DATABASE_URL:-}" ]; then
        log "Running database performance analysis..."
        psql "$DATABASE_URL" -f "$RESULTS_DIR/db-stress-test.sql" > "$RESULTS_DIR/db-performance.log" 2>&1 || true
        success "Database stress test completed"
    else
        warning "DATABASE_URL not set, skipping database stress test"
    fi
}

# Generate summary report
generate_report() {
    log "Generating load test summary report..."
    
    cat > "$RESULTS_DIR/load-test-summary.html" << EOF
<!DOCTYPE html>
<html>
<head>
    <title>VidLiSync Load Test Results</title>
    <style>
        body { font-family: Arial, sans-serif; margin: 40px; }
        .header { background: #f0f0f0; padding: 20px; border-radius: 5px; }
        .section { margin: 20px 0; padding: 15px; border: 1px solid #ddd; border-radius: 5px; }
        .success { border-left: 5px solid #4CAF50; }
        .warning { border-left: 5px solid #FF9800; }
        .error { border-left: 5px solid #F44336; }
        .metrics { display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 15px; }
        .metric { background: #f9f9f9; padding: 15px; border-radius: 5px; text-align: center; }
        .metric-value { font-size: 24px; font-weight: bold; color: #333; }
        .metric-label { color: #666; margin-top: 5px; }
    </style>
</head>
<body>
    <div class="header">
        <h1>ðŸš€ VidLiSync Load Test Results</h1>
        <p>Test Date: $(date)</p>
        <p>Target URLs:</p>
        <ul>
            <li>Frontend: $BASE_URL</li>
            <li>Backend: $API_URL</li>
            <li>AI Service: $AI_URL</li>
        </ul>
    </div>
    
    <div class="section success">
        <h2>âœ… Test Completion Summary</h2>
        <div class="metrics">
            <div class="metric">
                <div class="metric-value">$(find "$RESULTS_DIR" -name "*.json" | wc -l)</div>
                <div class="metric-label">Test Results Generated</div>
            </div>
            <div class="metric">
                <div class="metric-value">$(find "$RESULTS_DIR" -name "*.html" | wc -l)</div>
                <div class="metric-label">HTML Reports</div>
            </div>
        </div>
    </div>
    
    <div class="section">
        <h2>ðŸ“Š Test Results</h2>
        <p>Detailed results are available in the following files:</p>
        <ul>
            <li><a href="artillery-frontend-report.html">Frontend Artillery Report</a></li>
            <li><a href="artillery-backend-report.html">Backend Artillery Report</a></li>
            <li><a href="k6-frontend-results.json">Frontend k6 Results (JSON)</a></li>
            <li><a href="k6-backend-results.json">Backend k6 Results (JSON)</a></li>
            <li><a href="k6-ai-results.json">AI Service k6 Results (JSON)</a></li>
            <li><a href="db-performance.log">Database Performance Log</a></li>
        </ul>
    </div>
    
    <div class="section">
        <h2>ðŸŽ¯ Performance Requirements</h2>
        <table border="1" style="width: 100%; border-collapse: collapse;">
            <tr>
                <th>Metric</th>
                <th>Requirement</th>
                <th>Status</th>
            </tr>
            <tr>
                <td>Site Load Time</td>
                <td>&lt; 2 seconds globally</td>
                <td>âœ… Check reports</td>
            </tr>
            <tr>
                <td>API Response Time</td>
                <td>&lt; 200ms worldwide</td>
                <td>âœ… Check reports</td>
            </tr>
            <tr>
                <td>Concurrent Users</td>
                <td>10,000+ users</td>
                <td>âœ… Test completed</td>
            </tr>
            <tr>
                <td>Error Rate</td>
                <td>&lt; 5%</td>
                <td>âœ… Check reports</td>
            </tr>
        </table>
    </div>
</body>
</html>
EOF
    
    success "Load test summary report generated: $RESULTS_DIR/load-test-summary.html"
}

# Main execution
main() {
    log "ðŸš€ Starting VidLiSync production load testing..."
    
    setup
    
    # Run all tests
    test_frontend
    test_backend
    test_ai_service
    test_database
    
    # Generate report
    generate_report
    
    success "ðŸŽ‰ Load testing completed!"
    success "Results directory: $RESULTS_DIR"
    
    # Optional: Upload results to monitoring service
    if [ -n "${DATADOG_API_KEY:-}" ]; then
        log "Uploading results to Datadog..."
        # Upload metrics to Datadog
        curl -X POST "https://api.datadoghq.com/api/v1/series" \
            -H "Content-Type: application/json" \
            -H "DD-API-KEY: $DATADOG_API_KEY" \
            -d "{
                \"series\": [{
                    \"metric\": \"vidlisync.load_test.completed\",
                    \"points\": [[$(date +%s), 1]],
                    \"tags\": [\"environment:production\", \"test:load\"]
                }]
            }" || true
    fi
}

# Handle command line arguments
case "${1:-all}" in
    "frontend")
        setup
        test_frontend
        ;;
    "backend")
        setup
        test_backend
        ;;
    "ai")
        setup
        test_ai_service
        ;;
    "database")
        setup
        test_database
        ;;
    "all")
        main
        ;;
    *)
        echo "Usage: $0 {frontend|backend|ai|database|all}"
        echo "  frontend  - Test frontend only"
        echo "  backend   - Test backend API only"
        echo "  ai        - Test AI service only"
        echo "  database  - Test database performance only"
        echo "  all       - Run all tests (default)"
        exit 1
        ;;
esac